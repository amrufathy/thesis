\addcontentsline{toc}{chapter}{Abstract}

\begin{abstract}

% https://www.ldeo.columbia.edu/~martins/sen_sem/thesis_org.html
%Answers to these questions should be found in the abstract: 
%What did you do? 
%Why did you do it? What question were you trying to answer? 
%How did you do it? State methods.
%What did you learn? State major results. 
%Why does it matter? Point out at least one significant implication.

% -------------------------------

%Story generators can be used in a variety of situations. Human-AI interaction is a booming field with the widespread of voice assistants like Siri or Alexa. Complex queries (e.g. ``Help me plan a birthday'') require more narrative, to form a human-friendly answer, than simple ones (e.g. ``What's the weather today?''). Explainable AI is heavily in demand, where an AI system is asked to explain a certain decision, especially in sequential decision making. This resemble story generation in having a temporal component.

%Story generation systems still lack originality/creativity, suffer from repeated text, cannot generate coherent stories that adhere to a single theme, and are unable to generalize to different domains.

% -------------------------------


Even though we are currently experiencing a technological revolution, with virtual assistants becoming a vital part of it, many of these agents are still lacking when it comes to proper communication. Humans are natural storytellers, thus it is fitting that these Artificial Intelligence-powered agents are able to properly understand and tell stories.

Automated story generation is a field of AI where the goal is to create agents that tell \textit{good} stories. A story being good is subjective and hard to define. In this thesis, we will discuss and deal with some well-defined metrics to measure the quality of generated stories.

Previous methods relied on symbolic planning and knowledge databases to generate stories, which made them domain-rigid and limitedly coherent. Recently, neural-based approaches have shown more promise in terms of the quality of generated stories and their ability to reduce the need for knowledge databases. Nevertheless, these systems still lack originality, long-term coherence, and other problems.

In this study, we try to improve story generation by leveraging the knowledge of large pretrained models and utilizing extra training signals through a cycle-consistency framework. More formally, we exploit the dual tasks of text generation and summarization as means to improve the performance of the story generation task. We show that the cycle-consistency framework offers better results in text overlap and text diversity metrics.

\end{abstract}
