\addcontentsline{toc}{chapter}{Abstract}

\begin{abstract}

% https://www.ldeo.columbia.edu/~martins/sen_sem/thesis_org.html


Even though we are currently experiencing a technological revolution, with virtual assistants becoming a vital part of it, many of these agents are still lacking when it comes to proper communication. Humans are natural storytellers, thus it is fitting that these Artificial Intelligence-powered agents are able to properly understand and tell stories.

Automated story generation is a field of AI where the goal is to create agents that tell \textit{good} stories. A story being good is subjective and hard to define. In this thesis, we will discuss and deal with some well-defined metrics to measure the quality of generated stories.

Previous methods relied on symbolic planning and knowledge databases to generate stories, which made them domain-rigid and limitedly coherent. Recently, neural-based approaches have shown more promise in terms of the quality of generated stories and their ability to reduce the need for knowledge databases. Nevertheless, these systems still lack originality, long-term coherence, and other problems.

In this study, we try to improve story generation by leveraging the knowledge of large pretrained models and utilizing extra training signals through a cycle-consistency framework. More formally, we exploit the dual tasks of text generation and summarization as means to improve the performance of the story generation task. We show that the cycle-consistency framework offers better results in text overlap and text diversity metrics.

\end{abstract}
